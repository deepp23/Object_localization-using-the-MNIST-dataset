{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc4e069-597b-4c06-ac94-1f06ae92fbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 09:46:21.037513: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-14 09:46:21.041058: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-14 09:46:21.077585: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-14 09:46:21.896430: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 09:46:23.225282: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(train_data, label_data, image_size):\n",
    "    normalized_images = []\n",
    "    bounding_boxes = []\n",
    "    digit_classes = []\n",
    "    for image, label in zip(train_data, label_data):\n",
    "        enlarged_image = np.zeros((image_size, image_size), dtype=np.uint8)\n",
    "        x = np.random.randint(0, image_size - 28)\n",
    "        y = np.random.randint(0, image_size - 28)\n",
    "        enlarged_image[x:x + 28, y:y + 28] = image\n",
    "\n",
    "        bounding_box = [y, x, y + 28, x + 28]\n",
    "        bounding_boxes.append(bounding_box)\n",
    "\n",
    "        digit_class = tf.one_hot(label, depth=10)  # Corrected to not use expand_dims\n",
    "        digit_classes.append(digit_class)\n",
    "\n",
    "        normalized_image = enlarged_image / 255.0\n",
    "        normalized_images.append(normalized_image)\n",
    "\n",
    "    bounding_boxes = np.array(bounding_boxes, dtype=np.float32)\n",
    "    digit_classes = np.array(digit_classes, dtype=np.float32)\n",
    "    normalized_images = np.array(normalized_images, dtype=np.float32).reshape((-1, image_size, image_size, 1))\n",
    "    return normalized_images, bounding_boxes, digit_classes\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "train_images, train_bounding_boxes, train_digit_classes = preprocess(train_images, train_labels, 72)\n",
    "test_images, test_bounding_boxes, test_digit_classes = preprocess(test_images, test_labels, 72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05399cfc-a83e-41ce-8e7f-0ef1ff3831e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, (train_bounding_boxes, train_digit_classes)))\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c00e8bb-6e05-4d41-bfd0-cb49e8691618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_ = Input(shape=(72, 72, 1))\n",
    "x = Conv2D(16, (3, 3), activation='relu')(input_)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Regression Layer\n",
    "reg_output = Dense(4, name=\"regression\")(x)\n",
    "\n",
    "# Classifier\n",
    "cls_output = Dense(10, activation='softmax', name=\"classifier\")(x)\n",
    "\n",
    "model = Model(inputs=input_, outputs=[reg_output, cls_output])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'regression': 'mse',\n",
    "        'classifier': 'categorical_crossentropy'\n",
    "    },\n",
    "    metrics={\n",
    "        'regression': ['mse'],\n",
    "        'classifier': ['accuracy']\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fbd2c55-f599-4a6a-aa09-198caac93a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 49ms/step - classifier_accuracy: 0.1270 - loss: 82.1481 - regression_mse: 79.4471\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 46ms/step - classifier_accuracy: 0.2885 - loss: 3.1382 - regression_mse: 1.1648\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 47ms/step - classifier_accuracy: 0.5179 - loss: 1.9983 - regression_mse: 0.6230\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 47ms/step - classifier_accuracy: 0.7908 - loss: 1.1664 - regression_mse: 0.4932\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 46ms/step - classifier_accuracy: 0.8845 - loss: 0.7869 - regression_mse: 0.4112\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 47ms/step - classifier_accuracy: 0.9204 - loss: 0.6109 - regression_mse: 0.3494\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 45ms/step - classifier_accuracy: 0.9404 - loss: 0.5051 - regression_mse: 0.3085\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 46ms/step - classifier_accuracy: 0.9522 - loss: 0.4335 - regression_mse: 0.2750\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 45ms/step - classifier_accuracy: 0.9599 - loss: 0.3861 - regression_mse: 0.2547\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 46ms/step - classifier_accuracy: 0.9653 - loss: 0.3475 - regression_mse: 0.2373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f17ea4606a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16918f36-6f24-4d40-87db-986c38474061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f6da614-d513-4dbc-8042-c418c6c859be",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, (test_bounding_boxes, test_digit_classes)))\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c0646a7-7eb1-4eb9-a8aa-2f7201512f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 7s - 23ms/step - classifier_accuracy: 0.9393 - loss: 0.6155 - regression_mse: 0.3976\n",
      "loss: 0.6155493259429932\n",
      "compile_metrics: 0.939300000667572\n",
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_dataset, verbose=2)\n",
    "\n",
    "# Print the results\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value}\")\n",
    "\n",
    "print(\"Evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70891c8-7e7d-46fa-b353-d2383f58febc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
